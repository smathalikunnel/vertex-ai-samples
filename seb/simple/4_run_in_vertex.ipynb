{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212992e5-e28b-4612-a06b-1b2609ed6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820e875c-f3db-459d-8849-ff5084682558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://vertex_e2e_example/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -l europe-west1 gs://vertex_e2e_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a811a3bf-7a6b-4d12-a66f-6de1cb020c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"gs://vertex_e2e_example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "917e2f86-eed4-4d68-96bf-f06b3032faad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://vertex_e2e_example\n"
     ]
    }
   ],
   "source": [
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f229b1-3d83-4650-a727-f9687b55d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job = aiplatform.CustomTrainingJob(\n",
    "    #display_name=JOB_NAME,\n",
    "    display_name=\"first model on vertex\",\n",
    "    script_path=\"train.py\",\n",
    "    #container_uri=TRAIN_IMAGE,\n",
    "    container_uri=\"europe-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\",\n",
    "    #requirements=[\"google-cloud-bigquery>=2.20.0\"],\n",
    "    #model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    staging_bucket=bucket,\n",
    "    project='vf-grp-commercial-tst-explore',\n",
    "    location='europe-west1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622bbc41-9a26-458d-8ecf-4e9498540bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.utils.source_utils:Training script copied to:\n",
      "gs://vertex_e2e_example/aiplatform-2021-11-01-15:25:53.281-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "INFO:google.cloud.aiplatform.training_jobs:Training Output directory:\n",
      "gs://vertex_e2e_example/aiplatform-custom-training-2021-11-01-15:25:53.493 \n",
      "INFO:google.cloud.aiplatform.training_jobs:View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/europe-west1/training/7498581340502097920?project=387138108602\n",
      "INFO:google.cloud.aiplatform.training_jobs:View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/europe-west1/training/616870003647447040?project=387138108602\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/387138108602/locations/europe-west1/trainingPipelines/7498581340502097920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/387138108602/locations/europe-west1/trainingPipelines/7498581340502097920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/387138108602/locations/europe-west1/trainingPipelines/7498581340502097920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/387138108602/locations/europe-west1/trainingPipelines/7498581340502097920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/387138108602/locations/europe-west1/trainingPipelines/7498581340502097920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/387138108602/locations/europe-west1/trainingPipelines/7498581340502097920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Training failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. \\nTraceback (most recent call last):\\n  File \\\"/opt/conda/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n  File \\\"/opt/conda/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"/root/.local/lib/python3.7/site-packages/aiplatform_custom_trainer_script/task.py\\\", line 113, in <module>\\n    mode=\\'train\\')\\n  File \\\"/root/.local/lib/python3.7/site-packages/aiplatform_custom_trainer_script/task.py\\\", line 57, in create_dataset\\n    pattern, batch_size, CSV_COLUMNS, DEFAULTS)\\n  File \\\"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py\\\", line 479, in make_csv_dataset_v2\\n    filenames = _get_file_names(file_pattern, False)\\n  File \\\"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py\\\", line 1124, in _get_file_names\\n    raise ValueError(\\\"No files match %s.\\\" % file_pattern)\\nValueError: No files match ./data/taxi-train*.\\n\\nTo find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=387138108602&resource=ml_job%2Fjob_id%2F616870003647447040&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%22616870003647447040%22\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/75079444.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m        \u001b[0;31m# machine_type=TRAIN_COMPUTE,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmachine_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'n1-standard-4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0maccelerator_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataset, annotation_schema_uri, model_display_name, model_labels, base_output_dir, service_account, network, bigquery_destination, args, environment_variables, replica_count, machine_type, accelerator_type, accelerator_count, boot_disk_type, boot_disk_size_gb, reduction_server_replica_count, reduction_server_machine_type, reduction_server_container_uri, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, enable_web_access, tensorboard, sync)\u001b[0m\n\u001b[1;32m   2091\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduction_server_replica_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2094\u001b[0m         )\n\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, python_packager, dataset, annotation_schema_uri, worker_pool_specs, managed_model, args, environment_variables, base_output_dir, service_account, network, bigquery_destination, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, enable_web_access, tensorboard, reduction_server_container_uri, sync)\u001b[0m\n\u001b[1;32m   2334\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanaged_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m             \u001b[0mgcs_destination_uri_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_output_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m             \u001b[0mbigquery_destination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbigquery_destination\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m         )\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_run_job\u001b[0;34m(self, training_task_definition, training_task_inputs, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, annotation_schema_uri, model, gcs_destination_uri_prefix, bigquery_destination)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"View Training:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashboard_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_get_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mTraining\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_failed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_raise_failure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcode_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Training failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. \\nTraceback (most recent call last):\\n  File \\\"/opt/conda/lib/python3.7/runpy.py\\\", line 193, in _run_module_as_main\\n    \\\"__main__\\\", mod_spec)\\n  File \\\"/opt/conda/lib/python3.7/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"/root/.local/lib/python3.7/site-packages/aiplatform_custom_trainer_script/task.py\\\", line 113, in <module>\\n    mode=\\'train\\')\\n  File \\\"/root/.local/lib/python3.7/site-packages/aiplatform_custom_trainer_script/task.py\\\", line 57, in create_dataset\\n    pattern, batch_size, CSV_COLUMNS, DEFAULTS)\\n  File \\\"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py\\\", line 479, in make_csv_dataset_v2\\n    filenames = _get_file_names(file_pattern, False)\\n  File \\\"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py\\\", line 1124, in _get_file_names\\n    raise ValueError(\\\"No files match %s.\\\" % file_pattern)\\nValueError: No files match ./data/taxi-train*.\\n\\nTo find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=387138108602&resource=ml_job%2Fjob_id%2F616870003647447040&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%22616870003647447040%22\"\n"
     ]
    }
   ],
   "source": [
    "model = job.run(\n",
    "       # dataset=dataset,\n",
    "       # model_display_name=MODEL_DISPLAY_NAME,\n",
    "       # bigquery_destination=f\"bq://{PROJECT_ID}\",\n",
    "       # args=CMDARGS,\n",
    "        replica_count=1,\n",
    "       # machine_type=TRAIN_COMPUTE,\n",
    "    machine_type='n1-standard-4',\n",
    "        accelerator_count=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc54ab2-2c11-4a62-a258-ba22731992ca",
   "metadata": {},
   "source": [
    "#### above fails because the data was being picked up from a local file system; however for vertex ai training the data needs to be in gcs or bq location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a68e8-42e9-4877-9c26-3a91db18be1a",
   "metadata": {},
   "source": [
    "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/art_and_science_of_ml/solutions/export_data_from_bq_to_gcs.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386bb4a-f0ec-4c92-ba8b-1bd1d74ea2b0",
   "metadata": {},
   "source": [
    "%%writefile --append train.py\n",
    "\n",
    "tf.saved_model.save(model, os.environ[\"AIP_MODEL_DIR\"])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu:latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
